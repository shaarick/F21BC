{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "GoodNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "797d09f7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "id": "797d09f7",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6de6b7e5"
      },
      "source": [
        "data = pd.read_csv(\"./data_banknote_authentication.txt\", header=None)\n",
        "# seperate into input and output features\n",
        "X, Y = data.values[:, :-1], data.values[:, -1]\n",
        "Y = LabelEncoder().fit_transform(Y)\n",
        "# split into train and test datasets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "\n",
        "X_train = X_train.T\n",
        "X_test = X_test.T"
      ],
      "id": "6de6b7e5",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e81e7bd"
      },
      "source": [
        "def relu(Z):\n",
        "    return np.maximum(Z, 0)\n",
        "\n",
        "def tanh(Z):\n",
        "    return np.tanh(Z)\n",
        "\n",
        "def sigmoid(Z):\n",
        "    return 1/(1+np.exp(-Z))\n",
        "\n",
        "def softmax(Z):\n",
        "    A = np.exp(Z) / sum(np.exp(Z))\n",
        "    return A\n",
        "\n",
        "def relu_deriv(Z):\n",
        "    return Z > 0\n",
        "\n",
        "def tanh_deriv(Z):\n",
        "    return 1-np.tanh(Z)**2\n",
        "\n",
        "def sigmoid_deriv(Z):\n",
        "    sig = 1/(1+np.exp(-Z))\n",
        "    return sig * (1 - sig)\n",
        "\n",
        "def one_hot(Y):\n",
        "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
        "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
        "    one_hot_Y = one_hot_Y.T\n",
        "    return one_hot_Y"
      ],
      "id": "0e81e7bd",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "56d06807"
      },
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, layer_sizes, epochs, alpha, activations):\n",
        "            self.layer_sizes = layer_sizes\n",
        "            self.num_iters = epochs\n",
        "            self.learning_rate = alpha\n",
        "            self.activations = activations\n",
        "            self.params = {}\n",
        "            self.last = len(self.layer_sizes)\n",
        "            self.init_params();\n",
        "            \n",
        "    def __repr__(self):\n",
        "        return f\"ANN Hyperparameters\\nLayers: {self.layers_sizes}\\nLearning rate: {self.learning_rate} \\\n",
        "        \\nIterations: {self.num_iters}\"\n",
        "    \n",
        "    # Initalize the network with random weights and biases\n",
        "    def init_params(self):\n",
        "        params = self.params\n",
        "        for i in range(1, self.last):\n",
        "            params[f'W{i}'] = np.random.rand(self.layer_sizes[i], self.layer_sizes[i-1]) - 0.5\n",
        "            params[f'B{i}'] = np.random.rand(self.layer_sizes[i],1) - 0.5\n",
        "            \n",
        "    def forward_propagation(self, X):\n",
        "        # Pass X through the network \n",
        "        params = self.params\n",
        "        for i in range(1, self.last):\n",
        "            if i==1:\n",
        "                # For first layer compute dot with x\n",
        "                output = params[f'W{i}'].dot(X) + params[f'B{i}']\n",
        "            else: \n",
        "                # For all other layers compute with output of prev layer\n",
        "                output = params[f'W{i}'].dot(params[f'A{i-1}']) + params[f'B{i}']\n",
        "            if(i == self.last - 1):\n",
        "                # For final layer use softmax\n",
        "                activations = softmax(output)\n",
        "            else:\n",
        "                # For all other layers use the activ_fnc initalized in constructor\n",
        "                activ_fnc = self.activations[i-1]\n",
        "                activations = globals()[activ_fnc](output)\n",
        "            \n",
        "            params[f'Z{i}'] = output\n",
        "            params[f'A{i}'] = activations\n",
        "\n",
        "\n",
        "    def backward_propagation(self, X, Y):\n",
        "        ohY = one_hot(Y)\n",
        "        params = self.params\n",
        "        \n",
        "        for i in range(self.last - 1, 0, -1):\n",
        "            if(i == self.last - 1):\n",
        "                # For final layer calculate how wrong net is and compute gradients for weights and biases\n",
        "                dZ =  params[f'A{i}'] - ohY\n",
        "                params[f'dZ{i}'] = dZ\n",
        "                params[f'dW{i}'] = 1 / m * dZ.dot(params[f'A{i-1}'].T)\n",
        "                params[f'dB{i}'] = 1 / m * np.sum(dZ)\n",
        "            elif (i == 1):\n",
        "                # For first layer compute the gradients for weights and biases with input of dataset\n",
        "                dZ = params[f'W{i+1}'].T.dot(params[f'dZ{i+1}']) * globals()[f'{self.activations[i-1]}_deriv'](params[f'Z{i}'])\n",
        "                params[f'dZ{i}'] = dZ\n",
        "                params[f'dW{i}'] = 1 / m * dZ.dot(X.T)\n",
        "                params[f'dB{i}'] = 1 / m * np.sum(dZ)\n",
        "            else: \n",
        "                # For all other layers compute the gradients for weights and biases with the output of the prev layer\n",
        "                dZ = params[f'W{i+1}'].T.dot(params[f'dZ{i+1}']) * globals()[f'{self.activations[i-1]}_deriv'](params[f'Z{i}'])\n",
        "                params[f'dZ{i}'] = dZ\n",
        "                params[f'dW{i}'] = 1 / m * dZ.dot(params[f'A{i-1}'].T)\n",
        "                params[f'dB{i}'] = 1 / m * np.sum(dZ)\n",
        "\n",
        "    \n",
        "    def update_params(self, alpha):\n",
        "        # Update all layers based on the gradients calculated in back prop\n",
        "        params = self.params\n",
        "        for i in range(1, self.last):\n",
        "            params[f'W{i}'] =  params[f'W{i}'] - self.learning_rate * params[f'dW{i}']\n",
        "            params[f'B{i}'] =  params[f'B{i}'] - self.learning_rate * params[f'dB{i}']\n",
        "\n",
        "    def make_predictions(self, X):\n",
        "        self.forward_propagation(X)\n",
        "        predictions = self.get_predictions()\n",
        "        return predictions\n",
        "\n",
        "    def test_predictions(self, i):\n",
        "        curr = X_train[:, i, None]\n",
        "        print(\"label \", Y_train[i])\n",
        "        print(\"predicted \", self.make_predictions(curr)[0])\n",
        "\n",
        "    def get_predictions(self):\n",
        "        return np.argmax(self.params[f'A{self.last-1}'], 0)\n",
        "\n",
        "    def get_accuracy(self, predictions, Y):\n",
        "        return np.sum(predictions == Y) / Y.size\n",
        "    \n",
        "    def train(self, X, Y):\n",
        "        for i in range(self.num_iters):\n",
        "            self.forward_propagation(X)\n",
        "            self.backward_propagation(X, Y)\n",
        "            self.update_params(self.learning_rate)\n",
        "       \n",
        "            # Print accuracy every 10 iterations\n",
        "            if i % 1 == 0:\n",
        "                print(\"Iteration: \", i)\n",
        "                predictions = self.get_predictions()\n",
        "                print('Accuracy: ',self.get_accuracy(predictions, Y))\n",
        "                \n",
        "        return self.params"
      ],
      "id": "56d06807",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "228c2a4e"
      },
      "source": [
        "nn = NeuralNetwork([4,10,10,2], 500, 0.10, ['relu','relu'])"
      ],
      "id": "228c2a4e",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5da6ef7f",
        "outputId": "aa395fc6-53af-4d89-ff0b-22fc10471812"
      },
      "source": [
        "x = nn.train(X_train, Y_train)"
      ],
      "id": "5da6ef7f",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0\n",
            "Accuracy:  0.5669205658324266\n",
            "Iteration:  1\n",
            "Accuracy:  0.7181719260065288\n",
            "Iteration:  2\n",
            "Accuracy:  0.7562568008705114\n",
            "Iteration:  3\n",
            "Accuracy:  0.7671381936887922\n",
            "Iteration:  4\n",
            "Accuracy:  0.7812840043525572\n",
            "Iteration:  5\n",
            "Accuracy:  0.8204570184983678\n",
            "Iteration:  6\n",
            "Accuracy:  0.8683351468988031\n",
            "Iteration:  7\n",
            "Accuracy:  0.8813928182807399\n",
            "Iteration:  8\n",
            "Accuracy:  0.8933623503808488\n",
            "Iteration:  9\n",
            "Accuracy:  0.9031556039173014\n",
            "Iteration:  10\n",
            "Accuracy:  0.9129488574537541\n",
            "Iteration:  11\n",
            "Accuracy:  0.926006528835691\n",
            "Iteration:  12\n",
            "Accuracy:  0.9445048966267682\n",
            "Iteration:  13\n",
            "Accuracy:  0.9521218715995647\n",
            "Iteration:  14\n",
            "Accuracy:  0.9597388465723613\n",
            "Iteration:  15\n",
            "Accuracy:  0.9640914036996736\n",
            "Iteration:  16\n",
            "Accuracy:  0.9684439608269858\n",
            "Iteration:  17\n",
            "Accuracy:  0.970620239390642\n",
            "Iteration:  18\n",
            "Accuracy:  0.9749727965179543\n",
            "Iteration:  19\n",
            "Accuracy:  0.9782372143634385\n",
            "Iteration:  20\n",
            "Accuracy:  0.9793253536452666\n",
            "Iteration:  21\n",
            "Accuracy:  0.9793253536452666\n",
            "Iteration:  22\n",
            "Accuracy:  0.9815016322089227\n",
            "Iteration:  23\n",
            "Accuracy:  0.9836779107725789\n",
            "Iteration:  24\n",
            "Accuracy:  0.9836779107725789\n",
            "Iteration:  25\n",
            "Accuracy:  0.985854189336235\n",
            "Iteration:  26\n",
            "Accuracy:  0.9869423286180631\n",
            "Iteration:  27\n",
            "Accuracy:  0.9923830250272034\n",
            "Iteration:  28\n",
            "Accuracy:  0.9923830250272034\n",
            "Iteration:  29\n",
            "Accuracy:  0.9934711643090316\n",
            "Iteration:  30\n",
            "Accuracy:  0.9934711643090316\n",
            "Iteration:  31\n",
            "Accuracy:  0.9934711643090316\n",
            "Iteration:  32\n",
            "Accuracy:  0.9945593035908596\n",
            "Iteration:  33\n",
            "Accuracy:  0.9945593035908596\n",
            "Iteration:  34\n",
            "Accuracy:  0.9945593035908596\n",
            "Iteration:  35\n",
            "Accuracy:  0.9945593035908596\n",
            "Iteration:  36\n",
            "Accuracy:  0.9945593035908596\n",
            "Iteration:  37\n",
            "Accuracy:  0.9945593035908596\n",
            "Iteration:  38\n",
            "Accuracy:  0.9945593035908596\n",
            "Iteration:  39\n",
            "Accuracy:  0.9945593035908596\n",
            "Iteration:  40\n",
            "Accuracy:  0.9956474428726877\n",
            "Iteration:  41\n",
            "Accuracy:  0.9956474428726877\n",
            "Iteration:  42\n",
            "Accuracy:  0.9956474428726877\n",
            "Iteration:  43\n",
            "Accuracy:  0.9956474428726877\n",
            "Iteration:  44\n",
            "Accuracy:  0.9956474428726877\n",
            "Iteration:  45\n",
            "Accuracy:  0.9956474428726877\n",
            "Iteration:  46\n",
            "Accuracy:  0.9956474428726877\n",
            "Iteration:  47\n",
            "Accuracy:  0.9956474428726877\n",
            "Iteration:  48\n",
            "Accuracy:  0.9956474428726877\n",
            "Iteration:  49\n",
            "Accuracy:  0.9956474428726877\n",
            "Iteration:  50\n",
            "Accuracy:  0.9956474428726877\n",
            "Iteration:  51\n",
            "Accuracy:  0.9956474428726877\n",
            "Iteration:  52\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  53\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  54\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  55\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  56\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  57\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  58\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  59\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  60\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  61\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  62\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  63\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  64\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  65\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  66\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  67\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  68\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  69\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  70\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  71\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  72\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  73\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  74\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  75\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  76\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  77\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  78\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  79\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  80\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  81\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  82\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  83\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  84\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  85\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  86\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  87\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  88\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  89\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  90\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  91\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  92\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  93\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  94\n",
            "Accuracy:  0.9967355821545157\n",
            "Iteration:  95\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  96\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  97\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  98\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  99\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  100\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  101\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  102\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  103\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  104\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  105\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  106\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  107\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  108\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  109\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  110\n",
            "Accuracy:  0.9978237214363439\n",
            "Iteration:  111\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  112\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  113\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  114\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  115\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  116\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  117\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  118\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  119\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  120\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  121\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  122\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  123\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  124\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  125\n",
            "Accuracy:  0.998911860718172\n",
            "Iteration:  126\n",
            "Accuracy:  1.0\n",
            "Iteration:  127\n",
            "Accuracy:  1.0\n",
            "Iteration:  128\n",
            "Accuracy:  1.0\n",
            "Iteration:  129\n",
            "Accuracy:  1.0\n",
            "Iteration:  130\n",
            "Accuracy:  1.0\n",
            "Iteration:  131\n",
            "Accuracy:  1.0\n",
            "Iteration:  132\n",
            "Accuracy:  1.0\n",
            "Iteration:  133\n",
            "Accuracy:  1.0\n",
            "Iteration:  134\n",
            "Accuracy:  1.0\n",
            "Iteration:  135\n",
            "Accuracy:  1.0\n",
            "Iteration:  136\n",
            "Accuracy:  1.0\n",
            "Iteration:  137\n",
            "Accuracy:  1.0\n",
            "Iteration:  138\n",
            "Accuracy:  1.0\n",
            "Iteration:  139\n",
            "Accuracy:  1.0\n",
            "Iteration:  140\n",
            "Accuracy:  1.0\n",
            "Iteration:  141\n",
            "Accuracy:  1.0\n",
            "Iteration:  142\n",
            "Accuracy:  1.0\n",
            "Iteration:  143\n",
            "Accuracy:  1.0\n",
            "Iteration:  144\n",
            "Accuracy:  1.0\n",
            "Iteration:  145\n",
            "Accuracy:  1.0\n",
            "Iteration:  146\n",
            "Accuracy:  1.0\n",
            "Iteration:  147\n",
            "Accuracy:  1.0\n",
            "Iteration:  148\n",
            "Accuracy:  1.0\n",
            "Iteration:  149\n",
            "Accuracy:  1.0\n",
            "Iteration:  150\n",
            "Accuracy:  1.0\n",
            "Iteration:  151\n",
            "Accuracy:  1.0\n",
            "Iteration:  152\n",
            "Accuracy:  1.0\n",
            "Iteration:  153\n",
            "Accuracy:  1.0\n",
            "Iteration:  154\n",
            "Accuracy:  1.0\n",
            "Iteration:  155\n",
            "Accuracy:  1.0\n",
            "Iteration:  156\n",
            "Accuracy:  1.0\n",
            "Iteration:  157\n",
            "Accuracy:  1.0\n",
            "Iteration:  158\n",
            "Accuracy:  1.0\n",
            "Iteration:  159\n",
            "Accuracy:  1.0\n",
            "Iteration:  160\n",
            "Accuracy:  1.0\n",
            "Iteration:  161\n",
            "Accuracy:  1.0\n",
            "Iteration:  162\n",
            "Accuracy:  1.0\n",
            "Iteration:  163\n",
            "Accuracy:  1.0\n",
            "Iteration:  164\n",
            "Accuracy:  1.0\n",
            "Iteration:  165\n",
            "Accuracy:  1.0\n",
            "Iteration:  166\n",
            "Accuracy:  1.0\n",
            "Iteration:  167\n",
            "Accuracy:  1.0\n",
            "Iteration:  168\n",
            "Accuracy:  1.0\n",
            "Iteration:  169\n",
            "Accuracy:  1.0\n",
            "Iteration:  170\n",
            "Accuracy:  1.0\n",
            "Iteration:  171\n",
            "Accuracy:  1.0\n",
            "Iteration:  172\n",
            "Accuracy:  1.0\n",
            "Iteration:  173\n",
            "Accuracy:  1.0\n",
            "Iteration:  174\n",
            "Accuracy:  1.0\n",
            "Iteration:  175\n",
            "Accuracy:  1.0\n",
            "Iteration:  176\n",
            "Accuracy:  1.0\n",
            "Iteration:  177\n",
            "Accuracy:  1.0\n",
            "Iteration:  178\n",
            "Accuracy:  1.0\n",
            "Iteration:  179\n",
            "Accuracy:  1.0\n",
            "Iteration:  180\n",
            "Accuracy:  1.0\n",
            "Iteration:  181\n",
            "Accuracy:  1.0\n",
            "Iteration:  182\n",
            "Accuracy:  1.0\n",
            "Iteration:  183\n",
            "Accuracy:  1.0\n",
            "Iteration:  184\n",
            "Accuracy:  1.0\n",
            "Iteration:  185\n",
            "Accuracy:  1.0\n",
            "Iteration:  186\n",
            "Accuracy:  1.0\n",
            "Iteration:  187\n",
            "Accuracy:  1.0\n",
            "Iteration:  188\n",
            "Accuracy:  1.0\n",
            "Iteration:  189\n",
            "Accuracy:  1.0\n",
            "Iteration:  190\n",
            "Accuracy:  1.0\n",
            "Iteration:  191\n",
            "Accuracy:  1.0\n",
            "Iteration:  192\n",
            "Accuracy:  1.0\n",
            "Iteration:  193\n",
            "Accuracy:  1.0\n",
            "Iteration:  194\n",
            "Accuracy:  1.0\n",
            "Iteration:  195\n",
            "Accuracy:  1.0\n",
            "Iteration:  196\n",
            "Accuracy:  1.0\n",
            "Iteration:  197\n",
            "Accuracy:  1.0\n",
            "Iteration:  198\n",
            "Accuracy:  1.0\n",
            "Iteration:  199\n",
            "Accuracy:  1.0\n",
            "Iteration:  200\n",
            "Accuracy:  1.0\n",
            "Iteration:  201\n",
            "Accuracy:  1.0\n",
            "Iteration:  202\n",
            "Accuracy:  1.0\n",
            "Iteration:  203\n",
            "Accuracy:  1.0\n",
            "Iteration:  204\n",
            "Accuracy:  1.0\n",
            "Iteration:  205\n",
            "Accuracy:  1.0\n",
            "Iteration:  206\n",
            "Accuracy:  1.0\n",
            "Iteration:  207\n",
            "Accuracy:  1.0\n",
            "Iteration:  208\n",
            "Accuracy:  1.0\n",
            "Iteration:  209\n",
            "Accuracy:  1.0\n",
            "Iteration:  210\n",
            "Accuracy:  1.0\n",
            "Iteration:  211\n",
            "Accuracy:  1.0\n",
            "Iteration:  212\n",
            "Accuracy:  1.0\n",
            "Iteration:  213\n",
            "Accuracy:  1.0\n",
            "Iteration:  214\n",
            "Accuracy:  1.0\n",
            "Iteration:  215\n",
            "Accuracy:  1.0\n",
            "Iteration:  216\n",
            "Accuracy:  1.0\n",
            "Iteration:  217\n",
            "Accuracy:  1.0\n",
            "Iteration:  218\n",
            "Accuracy:  1.0\n",
            "Iteration:  219\n",
            "Accuracy:  1.0\n",
            "Iteration:  220\n",
            "Accuracy:  1.0\n",
            "Iteration:  221\n",
            "Accuracy:  1.0\n",
            "Iteration:  222\n",
            "Accuracy:  1.0\n",
            "Iteration:  223\n",
            "Accuracy:  1.0\n",
            "Iteration:  224\n",
            "Accuracy:  1.0\n",
            "Iteration:  225\n",
            "Accuracy:  1.0\n",
            "Iteration:  226\n",
            "Accuracy:  1.0\n",
            "Iteration:  227\n",
            "Accuracy:  1.0\n",
            "Iteration:  228\n",
            "Accuracy:  1.0\n",
            "Iteration:  229\n",
            "Accuracy:  1.0\n",
            "Iteration:  230\n",
            "Accuracy:  1.0\n",
            "Iteration:  231\n",
            "Accuracy:  1.0\n",
            "Iteration:  232\n",
            "Accuracy:  1.0\n",
            "Iteration:  233\n",
            "Accuracy:  1.0\n",
            "Iteration:  234\n",
            "Accuracy:  1.0\n",
            "Iteration:  235\n",
            "Accuracy:  1.0\n",
            "Iteration:  236\n",
            "Accuracy:  1.0\n",
            "Iteration:  237\n",
            "Accuracy:  1.0\n",
            "Iteration:  238\n",
            "Accuracy:  1.0\n",
            "Iteration:  239\n",
            "Accuracy:  1.0\n",
            "Iteration:  240\n",
            "Accuracy:  1.0\n",
            "Iteration:  241\n",
            "Accuracy:  1.0\n",
            "Iteration:  242\n",
            "Accuracy:  1.0\n",
            "Iteration:  243\n",
            "Accuracy:  1.0\n",
            "Iteration:  244\n",
            "Accuracy:  1.0\n",
            "Iteration:  245\n",
            "Accuracy:  1.0\n",
            "Iteration:  246\n",
            "Accuracy:  1.0\n",
            "Iteration:  247\n",
            "Accuracy:  1.0\n",
            "Iteration:  248\n",
            "Accuracy:  1.0\n",
            "Iteration:  249\n",
            "Accuracy:  1.0\n",
            "Iteration:  250\n",
            "Accuracy:  1.0\n",
            "Iteration:  251\n",
            "Accuracy:  1.0\n",
            "Iteration:  252\n",
            "Accuracy:  1.0\n",
            "Iteration:  253\n",
            "Accuracy:  1.0\n",
            "Iteration:  254\n",
            "Accuracy:  1.0\n",
            "Iteration:  255\n",
            "Accuracy:  1.0\n",
            "Iteration:  256\n",
            "Accuracy:  1.0\n",
            "Iteration:  257\n",
            "Accuracy:  1.0\n",
            "Iteration:  258\n",
            "Accuracy:  1.0\n",
            "Iteration:  259\n",
            "Accuracy:  1.0\n",
            "Iteration:  260\n",
            "Accuracy:  1.0\n",
            "Iteration:  261\n",
            "Accuracy:  1.0\n",
            "Iteration:  262\n",
            "Accuracy:  1.0\n",
            "Iteration:  263\n",
            "Accuracy:  1.0\n",
            "Iteration:  264\n",
            "Accuracy:  1.0\n",
            "Iteration:  265\n",
            "Accuracy:  1.0\n",
            "Iteration:  266\n",
            "Accuracy:  1.0\n",
            "Iteration:  267\n",
            "Accuracy:  1.0\n",
            "Iteration:  268\n",
            "Accuracy:  1.0\n",
            "Iteration:  269\n",
            "Accuracy:  1.0\n",
            "Iteration:  270\n",
            "Accuracy:  1.0\n",
            "Iteration:  271\n",
            "Accuracy:  1.0\n",
            "Iteration:  272\n",
            "Accuracy:  1.0\n",
            "Iteration:  273\n",
            "Accuracy:  1.0\n",
            "Iteration:  274\n",
            "Accuracy:  1.0\n",
            "Iteration:  275\n",
            "Accuracy:  1.0\n",
            "Iteration:  276\n",
            "Accuracy:  1.0\n",
            "Iteration:  277\n",
            "Accuracy:  1.0\n",
            "Iteration:  278\n",
            "Accuracy:  1.0\n",
            "Iteration:  279\n",
            "Accuracy:  1.0\n",
            "Iteration:  280\n",
            "Accuracy:  1.0\n",
            "Iteration:  281\n",
            "Accuracy:  1.0\n",
            "Iteration:  282\n",
            "Accuracy:  1.0\n",
            "Iteration:  283\n",
            "Accuracy:  1.0\n",
            "Iteration:  284\n",
            "Accuracy:  1.0\n",
            "Iteration:  285\n",
            "Accuracy:  1.0\n",
            "Iteration:  286\n",
            "Accuracy:  1.0\n",
            "Iteration:  287\n",
            "Accuracy:  1.0\n",
            "Iteration:  288\n",
            "Accuracy:  1.0\n",
            "Iteration:  289\n",
            "Accuracy:  1.0\n",
            "Iteration:  290\n",
            "Accuracy:  1.0\n",
            "Iteration:  291\n",
            "Accuracy:  1.0\n",
            "Iteration:  292\n",
            "Accuracy:  1.0\n",
            "Iteration:  293\n",
            "Accuracy:  1.0\n",
            "Iteration:  294\n",
            "Accuracy:  1.0\n",
            "Iteration:  295\n",
            "Accuracy:  1.0\n",
            "Iteration:  296\n",
            "Accuracy:  1.0\n",
            "Iteration:  297\n",
            "Accuracy:  1.0\n",
            "Iteration:  298\n",
            "Accuracy:  1.0\n",
            "Iteration:  299\n",
            "Accuracy:  1.0\n",
            "Iteration:  300\n",
            "Accuracy:  1.0\n",
            "Iteration:  301\n",
            "Accuracy:  1.0\n",
            "Iteration:  302\n",
            "Accuracy:  1.0\n",
            "Iteration:  303\n",
            "Accuracy:  1.0\n",
            "Iteration:  304\n",
            "Accuracy:  1.0\n",
            "Iteration:  305\n",
            "Accuracy:  1.0\n",
            "Iteration:  306\n",
            "Accuracy:  1.0\n",
            "Iteration:  307\n",
            "Accuracy:  1.0\n",
            "Iteration:  308\n",
            "Accuracy:  1.0\n",
            "Iteration:  309\n",
            "Accuracy:  1.0\n",
            "Iteration:  310\n",
            "Accuracy:  1.0\n",
            "Iteration:  311\n",
            "Accuracy:  1.0\n",
            "Iteration:  312\n",
            "Accuracy:  1.0\n",
            "Iteration:  313\n",
            "Accuracy:  1.0\n",
            "Iteration:  314\n",
            "Accuracy:  1.0\n",
            "Iteration:  315\n",
            "Accuracy:  1.0\n",
            "Iteration:  316\n",
            "Accuracy:  1.0\n",
            "Iteration:  317\n",
            "Accuracy:  1.0\n",
            "Iteration:  318\n",
            "Accuracy:  1.0\n",
            "Iteration:  319\n",
            "Accuracy:  1.0\n",
            "Iteration:  320\n",
            "Accuracy:  1.0\n",
            "Iteration:  321\n",
            "Accuracy:  1.0\n",
            "Iteration:  322\n",
            "Accuracy:  1.0\n",
            "Iteration:  323\n",
            "Accuracy:  1.0\n",
            "Iteration:  324\n",
            "Accuracy:  1.0\n",
            "Iteration:  325\n",
            "Accuracy:  1.0\n",
            "Iteration:  326\n",
            "Accuracy:  1.0\n",
            "Iteration:  327\n",
            "Accuracy:  1.0\n",
            "Iteration:  328\n",
            "Accuracy:  1.0\n",
            "Iteration:  329\n",
            "Accuracy:  1.0\n",
            "Iteration:  330\n",
            "Accuracy:  1.0\n",
            "Iteration:  331\n",
            "Accuracy:  1.0\n",
            "Iteration:  332\n",
            "Accuracy:  1.0\n",
            "Iteration:  333\n",
            "Accuracy:  1.0\n",
            "Iteration:  334\n",
            "Accuracy:  1.0\n",
            "Iteration:  335\n",
            "Accuracy:  1.0\n",
            "Iteration:  336\n",
            "Accuracy:  1.0\n",
            "Iteration:  337\n",
            "Accuracy:  1.0\n",
            "Iteration:  338\n",
            "Accuracy:  1.0\n",
            "Iteration:  339\n",
            "Accuracy:  1.0\n",
            "Iteration:  340\n",
            "Accuracy:  1.0\n",
            "Iteration:  341\n",
            "Accuracy:  1.0\n",
            "Iteration:  342\n",
            "Accuracy:  1.0\n",
            "Iteration:  343\n",
            "Accuracy:  1.0\n",
            "Iteration:  344\n",
            "Accuracy:  1.0\n",
            "Iteration:  345\n",
            "Accuracy:  1.0\n",
            "Iteration:  346\n",
            "Accuracy:  1.0\n",
            "Iteration:  347\n",
            "Accuracy:  1.0\n",
            "Iteration:  348\n",
            "Accuracy:  1.0\n",
            "Iteration:  349\n",
            "Accuracy:  1.0\n",
            "Iteration:  350\n",
            "Accuracy:  1.0\n",
            "Iteration:  351\n",
            "Accuracy:  1.0\n",
            "Iteration:  352\n",
            "Accuracy:  1.0\n",
            "Iteration:  353\n",
            "Accuracy:  1.0\n",
            "Iteration:  354\n",
            "Accuracy:  1.0\n",
            "Iteration:  355\n",
            "Accuracy:  1.0\n",
            "Iteration:  356\n",
            "Accuracy:  1.0\n",
            "Iteration:  357\n",
            "Accuracy:  1.0\n",
            "Iteration:  358\n",
            "Accuracy:  1.0\n",
            "Iteration:  359\n",
            "Accuracy:  1.0\n",
            "Iteration:  360\n",
            "Accuracy:  1.0\n",
            "Iteration:  361\n",
            "Accuracy:  1.0\n",
            "Iteration:  362\n",
            "Accuracy:  1.0\n",
            "Iteration:  363\n",
            "Accuracy:  1.0\n",
            "Iteration:  364\n",
            "Accuracy:  1.0\n",
            "Iteration:  365\n",
            "Accuracy:  1.0\n",
            "Iteration:  366\n",
            "Accuracy:  1.0\n",
            "Iteration:  367\n",
            "Accuracy:  1.0\n",
            "Iteration:  368\n",
            "Accuracy:  1.0\n",
            "Iteration:  369\n",
            "Accuracy:  1.0\n",
            "Iteration:  370\n",
            "Accuracy:  1.0\n",
            "Iteration:  371\n",
            "Accuracy:  1.0\n",
            "Iteration:  372\n",
            "Accuracy:  1.0\n",
            "Iteration:  373\n",
            "Accuracy:  1.0\n",
            "Iteration:  374\n",
            "Accuracy:  1.0\n",
            "Iteration:  375\n",
            "Accuracy:  1.0\n",
            "Iteration:  376\n",
            "Accuracy:  1.0\n",
            "Iteration:  377\n",
            "Accuracy:  1.0\n",
            "Iteration:  378\n",
            "Accuracy:  1.0\n",
            "Iteration:  379\n",
            "Accuracy:  1.0\n",
            "Iteration:  380\n",
            "Accuracy:  1.0\n",
            "Iteration:  381\n",
            "Accuracy:  1.0\n",
            "Iteration:  382\n",
            "Accuracy:  1.0\n",
            "Iteration:  383\n",
            "Accuracy:  1.0\n",
            "Iteration:  384\n",
            "Accuracy:  1.0\n",
            "Iteration:  385\n",
            "Accuracy:  1.0\n",
            "Iteration:  386\n",
            "Accuracy:  1.0\n",
            "Iteration:  387\n",
            "Accuracy:  1.0\n",
            "Iteration:  388\n",
            "Accuracy:  1.0\n",
            "Iteration:  389\n",
            "Accuracy:  1.0\n",
            "Iteration:  390\n",
            "Accuracy:  1.0\n",
            "Iteration:  391\n",
            "Accuracy:  1.0\n",
            "Iteration:  392\n",
            "Accuracy:  1.0\n",
            "Iteration:  393\n",
            "Accuracy:  1.0\n",
            "Iteration:  394\n",
            "Accuracy:  1.0\n",
            "Iteration:  395\n",
            "Accuracy:  1.0\n",
            "Iteration:  396\n",
            "Accuracy:  1.0\n",
            "Iteration:  397\n",
            "Accuracy:  1.0\n",
            "Iteration:  398\n",
            "Accuracy:  1.0\n",
            "Iteration:  399\n",
            "Accuracy:  1.0\n",
            "Iteration:  400\n",
            "Accuracy:  1.0\n",
            "Iteration:  401\n",
            "Accuracy:  1.0\n",
            "Iteration:  402\n",
            "Accuracy:  1.0\n",
            "Iteration:  403\n",
            "Accuracy:  1.0\n",
            "Iteration:  404\n",
            "Accuracy:  1.0\n",
            "Iteration:  405\n",
            "Accuracy:  1.0\n",
            "Iteration:  406\n",
            "Accuracy:  1.0\n",
            "Iteration:  407\n",
            "Accuracy:  1.0\n",
            "Iteration:  408\n",
            "Accuracy:  1.0\n",
            "Iteration:  409\n",
            "Accuracy:  1.0\n",
            "Iteration:  410\n",
            "Accuracy:  1.0\n",
            "Iteration:  411\n",
            "Accuracy:  1.0\n",
            "Iteration:  412\n",
            "Accuracy:  1.0\n",
            "Iteration:  413\n",
            "Accuracy:  1.0\n",
            "Iteration:  414\n",
            "Accuracy:  1.0\n",
            "Iteration:  415\n",
            "Accuracy:  1.0\n",
            "Iteration:  416\n",
            "Accuracy:  1.0\n",
            "Iteration:  417\n",
            "Accuracy:  1.0\n",
            "Iteration:  418\n",
            "Accuracy:  1.0\n",
            "Iteration:  419\n",
            "Accuracy:  1.0\n",
            "Iteration:  420\n",
            "Accuracy:  1.0\n",
            "Iteration:  421\n",
            "Accuracy:  1.0\n",
            "Iteration:  422\n",
            "Accuracy:  1.0\n",
            "Iteration:  423\n",
            "Accuracy:  1.0\n",
            "Iteration:  424\n",
            "Accuracy:  1.0\n",
            "Iteration:  425\n",
            "Accuracy:  1.0\n",
            "Iteration:  426\n",
            "Accuracy:  1.0\n",
            "Iteration:  427\n",
            "Accuracy:  1.0\n",
            "Iteration:  428\n",
            "Accuracy:  1.0\n",
            "Iteration:  429\n",
            "Accuracy:  1.0\n",
            "Iteration:  430\n",
            "Accuracy:  1.0\n",
            "Iteration:  431\n",
            "Accuracy:  1.0\n",
            "Iteration:  432\n",
            "Accuracy:  1.0\n",
            "Iteration:  433\n",
            "Accuracy:  1.0\n",
            "Iteration:  434\n",
            "Accuracy:  1.0\n",
            "Iteration:  435\n",
            "Accuracy:  1.0\n",
            "Iteration:  436\n",
            "Accuracy:  1.0\n",
            "Iteration:  437\n",
            "Accuracy:  1.0\n",
            "Iteration:  438\n",
            "Accuracy:  1.0\n",
            "Iteration:  439\n",
            "Accuracy:  1.0\n",
            "Iteration:  440\n",
            "Accuracy:  1.0\n",
            "Iteration:  441\n",
            "Accuracy:  1.0\n",
            "Iteration:  442\n",
            "Accuracy:  1.0\n",
            "Iteration:  443\n",
            "Accuracy:  1.0\n",
            "Iteration:  444\n",
            "Accuracy:  1.0\n",
            "Iteration:  445\n",
            "Accuracy:  1.0\n",
            "Iteration:  446\n",
            "Accuracy:  1.0\n",
            "Iteration:  447\n",
            "Accuracy:  1.0\n",
            "Iteration:  448\n",
            "Accuracy:  1.0\n",
            "Iteration:  449\n",
            "Accuracy:  1.0\n",
            "Iteration:  450\n",
            "Accuracy:  1.0\n",
            "Iteration:  451\n",
            "Accuracy:  1.0\n",
            "Iteration:  452\n",
            "Accuracy:  1.0\n",
            "Iteration:  453\n",
            "Accuracy:  1.0\n",
            "Iteration:  454\n",
            "Accuracy:  1.0\n",
            "Iteration:  455\n",
            "Accuracy:  1.0\n",
            "Iteration:  456\n",
            "Accuracy:  1.0\n",
            "Iteration:  457\n",
            "Accuracy:  1.0\n",
            "Iteration:  458\n",
            "Accuracy:  1.0\n",
            "Iteration:  459\n",
            "Accuracy:  1.0\n",
            "Iteration:  460\n",
            "Accuracy:  1.0\n",
            "Iteration:  461\n",
            "Accuracy:  1.0\n",
            "Iteration:  462\n",
            "Accuracy:  1.0\n",
            "Iteration:  463\n",
            "Accuracy:  1.0\n",
            "Iteration:  464\n",
            "Accuracy:  1.0\n",
            "Iteration:  465\n",
            "Accuracy:  1.0\n",
            "Iteration:  466\n",
            "Accuracy:  1.0\n",
            "Iteration:  467\n",
            "Accuracy:  1.0\n",
            "Iteration:  468\n",
            "Accuracy:  1.0\n",
            "Iteration:  469\n",
            "Accuracy:  1.0\n",
            "Iteration:  470\n",
            "Accuracy:  1.0\n",
            "Iteration:  471\n",
            "Accuracy:  1.0\n",
            "Iteration:  472\n",
            "Accuracy:  1.0\n",
            "Iteration:  473\n",
            "Accuracy:  1.0\n",
            "Iteration:  474\n",
            "Accuracy:  1.0\n",
            "Iteration:  475\n",
            "Accuracy:  1.0\n",
            "Iteration:  476\n",
            "Accuracy:  1.0\n",
            "Iteration:  477\n",
            "Accuracy:  1.0\n",
            "Iteration:  478\n",
            "Accuracy:  1.0\n",
            "Iteration:  479\n",
            "Accuracy:  1.0\n",
            "Iteration:  480\n",
            "Accuracy:  1.0\n",
            "Iteration:  481\n",
            "Accuracy:  1.0\n",
            "Iteration:  482\n",
            "Accuracy:  1.0\n",
            "Iteration:  483\n",
            "Accuracy:  1.0\n",
            "Iteration:  484\n",
            "Accuracy:  1.0\n",
            "Iteration:  485\n",
            "Accuracy:  1.0\n",
            "Iteration:  486\n",
            "Accuracy:  1.0\n",
            "Iteration:  487\n",
            "Accuracy:  1.0\n",
            "Iteration:  488\n",
            "Accuracy:  1.0\n",
            "Iteration:  489\n",
            "Accuracy:  1.0\n",
            "Iteration:  490\n",
            "Accuracy:  1.0\n",
            "Iteration:  491\n",
            "Accuracy:  1.0\n",
            "Iteration:  492\n",
            "Accuracy:  1.0\n",
            "Iteration:  493\n",
            "Accuracy:  1.0\n",
            "Iteration:  494\n",
            "Accuracy:  1.0\n",
            "Iteration:  495\n",
            "Accuracy:  1.0\n",
            "Iteration:  496\n",
            "Accuracy:  1.0\n",
            "Iteration:  497\n",
            "Accuracy:  1.0\n",
            "Iteration:  498\n",
            "Accuracy:  1.0\n",
            "Iteration:  499\n",
            "Accuracy:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c424b4dd"
      },
      "source": [
        "preds = nn.make_predictions(X_test)"
      ],
      "id": "c424b4dd",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "373383d3",
        "outputId": "187cdda7-775e-48a0-eef8-a2e9403b640b"
      },
      "source": [
        "nn.test_predictions(1)"
      ],
      "id": "373383d3",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label  1\n",
            "predicted  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78a9f845",
        "outputId": "46b8256d-1589-432d-e2cd-1f6bc33d547e"
      },
      "source": [
        "n"
      ],
      "id": "78a9f845",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzFXpdR4mXVW"
      },
      "source": [
        ""
      ],
      "id": "SzFXpdR4mXVW",
      "execution_count": 9,
      "outputs": []
    }
  ]
}
